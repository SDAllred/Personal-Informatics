{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 97.6333333333\n",
      "Decision Tree: 95.1666666667\n",
      "Logistic Regression: 96.1666666667\n",
      "K-Nearest Neighbors: 89.6\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm, linear_model, neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Get Data from CSV\n",
    "def process_csv(file):\n",
    "    headers = []\n",
    "    data =  []\n",
    "    csv_data = csv.reader(open(file))\n",
    "    next(csv_data)\n",
    "    for i, row in enumerate(csv_data):\n",
    "      if i == 0:\n",
    "        headers = row\n",
    "       # continue;\n",
    "      field = []\n",
    "      for i in range(len(headers)):\n",
    "        field.append(float(row[i]))\n",
    "      data.append(field)\n",
    "    return data\n",
    "    \n",
    "## Take mean of each column\n",
    "def mean(A):\n",
    "    ten = np.asarray(A)\n",
    "    avg = []\n",
    "    for i in range(len(ten[0])):\n",
    "        avg.append(sum(ten[:,i])/len(ten))\n",
    "    return avg\n",
    "    \n",
    "\n",
    "#Take standard deviation of each column\n",
    "def std(A):\n",
    "    ten = np.asarray(A)\n",
    "    avg = []\n",
    "    for i in range(len(ten[0])):\n",
    "        avg.append(np.std(ten[:,i]))\n",
    "    return avg\n",
    "\n",
    "\n",
    "#Extract features and randomly split data into test and train for each activity.\n",
    "#This method handles data collected in .5 second intervals\n",
    "def getFeat20(data):\n",
    "\n",
    "    features = []\n",
    "    for j in range(30):\n",
    "        t = j * 20\n",
    "        tempTen = []\n",
    "        for i in range(t, t+20):\n",
    "            tempTen.append(data[i])\n",
    "        m = mean(tempTen)\n",
    "        n = std(tempTen)\n",
    "        n.pop(0)\n",
    "        f = m + n\n",
    "        features.append(f)\n",
    "\n",
    "    random.shuffle(features)\n",
    "\n",
    "    train_data = features[0:24]\n",
    "    test_data = features[24:30]\n",
    "\n",
    "    return train_data, test_data \n",
    "\n",
    "#Extract features and randomly split data into test and train for each activity.\n",
    "#This method handles data collected in .1 second intervals\n",
    "def getFeat100(data):\n",
    "\n",
    "    features = []\n",
    "    for j in range(30):\n",
    "        t = j * 100\n",
    "        tempTen = []\n",
    "        for i in range(t, t+100):\n",
    "            tempTen.append(data[i])\n",
    "        m = mean(tempTen)\n",
    "        n = std(tempTen)\n",
    "        n.pop(0)\n",
    "        f = m + n\n",
    "        features.append(f)\n",
    "\n",
    "    random.shuffle(features)\n",
    "\n",
    "    train_data = features[0:24]\n",
    "    test_data = features[24:30]\n",
    "\n",
    "    return train_data, test_data \n",
    "\n",
    "## Runs training and test sets through learning algorithms\n",
    "def MLrun(drive, rest, stair, run, walk):\n",
    "\n",
    "\n",
    "    trd,tsd  = getFeat100(drive)\n",
    "    trr,tsr  = getFeat100(rest)\n",
    "    trs,tss  = getFeat20(stair)\n",
    "    trrun,tsrun = getFeat100(run)\n",
    "    trw,tsw  = getFeat100(walk)\n",
    "\n",
    "\n",
    "    train = trd + trr + trs + trrun + trw\n",
    "\n",
    "    random.shuffle(train)\n",
    "\n",
    "    test = tsd + tsr + tss + tsrun + tsw\n",
    "\n",
    "    random.shuffle(test)\n",
    "\n",
    "    train = np.asarray(train)\n",
    "    test = np.asarray(test)\n",
    "\n",
    "    trainX = train[:,1:12]\n",
    "\n",
    "    trainY = train[:,0]\n",
    "\n",
    "    testX = test[:,1:12]\n",
    "\n",
    "    testY = test[:,0]\n",
    "\n",
    "\n",
    "    ############ Support Vector Machine ############\n",
    "    SVM1 = svm.SVC(kernel='linear')\n",
    "    SVM1.fit(trainX, trainY)\n",
    "\n",
    "    svmP = SVM1.predict(testX)\n",
    "\n",
    "    score = SVM1.score(testX, testY) * 100\n",
    "\n",
    "    ############ Decision Tree ############\n",
    "    DT = DecisionTreeClassifier()\n",
    "    DT.fit(trainX, trainY)\n",
    "\n",
    "    dtP = DT.predict(testX)\n",
    "\n",
    "    score2 = DT.score(testX, testY) * 100\n",
    "\n",
    "    ############ Logistic Regression ############\n",
    "    log = linear_model.LogisticRegression()\n",
    "    log.fit(trainX, trainY)\n",
    "    logP = log.predict(testX)\n",
    "\n",
    "    score3 = log.score(testX, testY) * 100\n",
    "\n",
    "    ############ K-Nearest Neighbors ############\n",
    "    KNN = neighbors.KNeighborsClassifier()\n",
    "    KNN.fit(trainX, trainY)\n",
    "    knnP = KNN.predict(testX)\n",
    "\n",
    "    score4 = KNN.score(testX, testY) * 100\n",
    "\n",
    "\n",
    "    return score, score2, score3, score4\n",
    "\n",
    "\n",
    "############### Run Experiment ###############\n",
    "\n",
    "stair1 = \"Stairs.csv\"\n",
    "rest1 = \"Rest10.csv\"\n",
    "run1 = \"Run.csv\"\n",
    "drive1 = \"Drive10.csv\"\n",
    "walk1 = \"Walk.csv\"\n",
    "\n",
    "\n",
    "stair = process_csv(stair1)\n",
    "rest = process_csv(rest1)\n",
    "run = process_csv(run1)\n",
    "drive = process_csv(drive1)\n",
    "walk = process_csv(walk1)\n",
    "\n",
    "\n",
    "totSVM = 0\n",
    "totDT = 0\n",
    "totLOG = 0\n",
    "totKNN = 0\n",
    "\n",
    "# iterations\n",
    "N = 100\n",
    "\n",
    "for i in range(N):\n",
    "\n",
    "    SVM, DT, LOG, KNN = MLrun(drive, rest, stair, run, walk)    \n",
    "    totSVM += SVM\n",
    "    totDT += DT\n",
    "    totLOG += LOG\n",
    "    totKNN += KNN\n",
    "\n",
    "avgSVM = totSVM/N\n",
    "avgDT = totDT/N\n",
    "avgLOG = totLOG/N\n",
    "avgKNN = totKNN/N\n",
    " \n",
    "print \"SVM:\",avgSVM\n",
    "\n",
    "print \"Decision Tree:\",avgDT\n",
    "\n",
    "print \"Logistic Regression:\",avgLOG\n",
    "\n",
    "print \"K-Nearest Neighbors:\",avgKNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
